package com.hellion23.tuplediff.api.stream.json;

import com.hellion23.tuplediff.api.compare.ComparableLinkedHashMap;
import com.hellion23.tuplediff.api.model.TDException;
import com.hellion23.tuplediff.api.model.TDStreamMetaData;
import com.hellion23.tuplediff.api.model.TDTuple;
import com.hellion23.tuplediff.api.stream.AbstractBufferingTDStream;
import com.hellion23.tuplediff.api.stream.source.StreamSource;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.*;

/**
 * JSONTDStream converts a JSON file source into a stream of TDTuples.
 * JSON objects do not abide to any schema and therefore neither typing nor field members can be definitively
 * determined by inspecting the first JSON object in an array or map, making a definitive schema impossible until
 * the entire stream is read, which consumes a significant amount of memory. For example, if a member value is null,
 * we don't know what the type is or if a member value is null and not present in the Object definition. Same if we
 * have 0 tuples in the collection.
 * The JSON source should already be sorted; if not, the ENTIRE file will be read into memory and sorted by the
 * primary key before comparison can begin. If it is not sorted, the entire  JSON stream will be read in and then
 * sorted prior to comparing. This can result in OutOfMemoryExceptions.
 *
 * TODO: Fix this?
 * The TDTuples generated by this Stream guarantees that the the depth = 0 (i.e. JSON members that are STRING,
 * NUMBER, BOOLEAN, NULL) will get converted to it's native Java class of String.class, BigDecimal.clsss, Boolean.class
 * and null respectively. The JSONTupe.OBJECT and JSONType.ARRAY will remain wrapped in a JSONValue object (as well
 * as the contained JSONValue objects). This means that a mutli-depth JSON, e.g. map of arrays will only be compared
 * correctly if the comparing stream is also a JSON Stream (JSONValues themselves are comparable, but only to
 * other JSONValues). Comparing hierarchical tuple values is a dangerous business as the metadata itself would need
 * to be multi-layered as well. Don't want to currently dive into this kind of complexity here unless a need arises
 * where we have to compare xml vs json or something bizarre like this.
 *
 */
public class JSONTDStream extends AbstractBufferingTDStream<TDStreamMetaData, TDTuple, JSONMember > {
    private final static Logger LOG = LoggerFactory.getLogger(JSONTDStream.class);
    public static String TD_FIELD_NAME = "TD_FIELD_NAME";

    StreamSource streamSource;
    List<String> primaryKey;
    String name;
    boolean isSorted;
    String pathToTuples;
    List<JSONTDColumn> interestedColumns = null;
    JSONStreamParser jParser = null;
    List<String> columnNames;

    /**
     * Full constructor.
     *
     * @param name Name of the stream
     * @param streamSource The InputStream of the JSON. This can be from a File or from a RESTful call, etc...
     *                The Stream at this point is *not* opened, until the get() is called during the open() process.
     * @param primaryKeyPaths The primary key list to sort the tuples by prior to comparing. If none is provided,
     *                and the readToPath points to a JSON Object (instead of an array), the key is the member name
     *                of the JSON object and will be called "TD_FIELD_NAME".
     * @param isSorted If the tuples as streamed is already sorted by the primary key.
     * @param pathToTuples This is the path to the actual tuple set; which could be embedded deep into the JSON stream.
     * @param interestedColumns Interested Column MetaData. This defines the fields that will be compared along with the
     *                 JSON type. This eliminates the potential for "guesswork" when a field is defined is present in
     *                 one tuple but not in another. Or if there are 0 tuples.
     */
    public JSONTDStream (String name,
                         StreamSource streamSource,
                         List<String> primaryKeyPaths,
                         boolean isSorted,
                         String pathToTuples,
                         List<JSONTDColumn> interestedColumns
     ) {
        super(name, 1);
        this.streamSource = streamSource;
        this.primaryKey = primaryKeyPaths;
        this.isSorted = isSorted;
        this.pathToTuples = pathToTuples;
        this.interestedColumns = interestedColumns;
    }

    /**
     * Ascertain the most accurate column name and type by peeking at all the tuples in the buffer.
     * @param column
     * @return
     */
    protected JSONTDColumn bestColumn (JSONTDColumn column) {
        JSONTDColumn best = column;
        JSONType type = column.getJSONType();
        String label = column.getLabel();

        for (JSONMember peek: peekAll()) {
            ComparableLinkedHashMap<String, JSONValue> m = peek.getElement();
            JSONValue val = m.get(label);
            // Uh oh, can't find, maybe the columnName used to do lookup doesn't match. Will need to iterate
            // the entire object to find the value.
            if (val == null) {
                for (Map.Entry<String, JSONValue> me : m.entrySet()) {
                    if (me.getKey().equalsIgnoreCase(label)) {
                        label = me.getKey();
                        val = me.getValue();
                        break;
                    }
                }
            }
            if (val == null) {
                throw new TDException(label + " STREAM Cannot find JSON column " + column);
            }
            else if (type == val.getJSONType() && type != JSONType.NULL) {
                best = new JSONTDColumn(type, label);
                break;
            }
            else if (type == JSONType.NULL && val.getJSONType() != JSONType.NULL ){
                best = new JSONTDColumn(val.getJSONType(), label);
            }
        }
        return best;
    }

    @Override
    public void openStream() throws Exception {
        jParser = new JSONStreamParser(streamSource, pathToTuples);
        jParser.open();
    }

    @Override
    protected TDStreamMetaData constructMetaData() {
        List<JSONTDColumn> columns = new LinkedList<>();
        this.columnNames = new LinkedList<>();

        // Columns have not been defined. We must peek ahead some tuples to try to ascertain what the metadata
        // should be.
        if (interestedColumns == null || interestedColumns.size() == 0) {
            List<JSONMember> peek = peekAll();
            if (peek.size() ==0) {
                throw new TDException(name + " STREAM cannot ascertain meta data when JSONStream has no tuples. " +
                        " If no tuples from this Stream is an expected use case, then interested columns must be " +
                        "defined. ");
            }
            Map<String, JSONTDColumn> cols = new LinkedHashMap<>();

            // For each look ahead JSON tuple,
            for (JSONMember jsonTuple : peek) {
                // Review every name value pair
                for (Map.Entry<String, JSONValue> fv : jsonTuple.getElement().entrySet()) {
                    // Check to see if the column map contains a column.
                    JSONTDColumn col = cols.get(fv.getKey());
                    // If not add it as a new column.
                    if (col == null) {
                        cols.put(fv.getKey(), new JSONTDColumn(fv.getValue().getJSONType(), fv.getKey()));
                    }
                    else {
                        // If the type we've stored is a null, this is a placeholder because the null value
                        // is not typed. So if one of the peeked items has something other than NULL, we should
                        // use this typing instead.
                        if (col.getJSONType() == JSONType.NULL && fv.getValue().getJSONType() != JSONType.NULL) {
                            cols.put(fv.getKey(), new JSONTDColumn(fv.getValue().getJSONType(), fv.getKey()));
                        }
                    }
                }
            }
            // Put them into the column in the order, close to how they appear in the tuple.
            for (Map.Entry<String, JSONTDColumn> me : cols.entrySet()) {
                this.columnNames.add(me.getKey());
                columns.add(me.getValue());
            }
        }
        else {
            // If user has already defined interested columns
            for (JSONTDColumn column : interestedColumns) {
                JSONTDColumn bestColumn = bestColumn(column);
                this.columnNames.add(bestColumn.getName());
                columns.add(bestColumn);
            }
        }

        if (primaryKey == null || primaryKey.size() == 0) {
            this.columnNames.add(TD_FIELD_NAME);
            columns.add(0, new JSONTDColumn(JSONType.STRING, TD_FIELD_NAME));
        }

        return new TDStreamMetaData(columns);
    }

    @Override
    protected TDTuple constructTuple(JSONMember jsonMember) {
        List<Comparable> values = new LinkedList<>();
        ComparableLinkedHashMap<String, JSONValue> map = jsonMember.getElement();
        if (map == null) {
            throw new TDException("Cannot construct a TDTuple unless the JSONType is a JSONObject. Naked " +
                    " json values such as numbers and strings cannot be converted into a  tuple: " + jsonMember);
        }
        for (String columnName : columnNames) {
            // Use map key as primary key. 
            if (columnName == TD_FIELD_NAME) {
                // the field name itself is the value of the key.
                values.add(jsonMember.getField());
            }
            else {
                // Get the underlying wrapped Comparable object.
                Comparable comparable = map.get(columnName).getComparable();
                //TODO: Future support of tuple elements that are hierarchical? Currently, this only unwraps the 1st tier.
                values.add(comparable);
            }
        }
        return new TDTuple(metadata, values);
    }

    @Override
    protected Iterator<JSONMember> iterator() {
        return jParser;
    }

    @Override
    protected void closeStream() throws Exception {
        streamSource.close();
    }

}
